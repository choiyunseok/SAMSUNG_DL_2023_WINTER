{"cells":[{"cell_type":"markdown","metadata":{"id":"D9UUcbMe5uHd"},"source":["# Day4-1 : VGG, RESNET model simple Implementation with CIFAR10 dataset (45 min)\n","#### 이번 실습에서는 CNN 아키텍쳐 중 가장 대표적인 VGG과 RESNET 모델을 간단히 구현해보고 CIFAR-10 데이터셋에 대해 학습 및 Inference를 해볼 계획입니다."]},{"cell_type":"markdown","metadata":{"id":"pMY3CPV4ebV2"},"source":["## Example 1) VGG16 모델 구현\n","- [doc] (https://arxiv.org/pdf/1409.1556.pdf)\n","\n","![image.png](http://drive.google.com/uc?id=1E6MVIcFCsImwWQGOhC-8KUQqAe2W_I28)\n","\n","![image.png](http://drive.google.com/uc?id=1jT9jhqMzEaHoma5xvro5jf6PFOq7FlLJ)\n","\n","![image.png](http://drive.google.com/uc?id=17DgT11woHwXACEGOfvkVd8pYmxRI7vQl)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"jbce4wfMMTqv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703139745226,"user_tz":-540,"elapsed":24932,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}},"outputId":"0d3178d7-bc08-4ef0-a531-4017e47b780e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 51847240.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/cifar-10-python.tar.gz to ../data\n","Files already downloaded and verified\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import transforms, datasets, utils\n","from torchsummary import summary\n","import matplotlib.pyplot as plt\n","\n","# DEVICE 설정\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","\n","# Parameter 설정\n","EPOCHS = 10\n","BATCH_SIZE = 64\n","LR = 0.0001\n","\n","# Transform 설정\n","transform_CIFAR10 = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","])\n","\n","# Dataset 설정\n","train_dataset = datasets.CIFAR10(root = '../data',\n","                                         train = True,\n","                                         download = True,\n","                                         transform = transform_CIFAR10)\n","\n","test_dataset = datasets.CIFAR10(root = '../data',\n","                                train = False,\n","                                download = True,\n","                                transform = transform_CIFAR10)\n","\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                           batch_size = BATCH_SIZE,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","                                          batch_size = BATCH_SIZE,\n","                                          shuffle=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"_JeDJmfNuN0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703140388820,"user_tz":-540,"elapsed":1621,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}},"outputId":"6c03135a-3a8b-4d3f-c79d-8ecf10e1774c"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","              ReLU-2           [-1, 64, 32, 32]               0\n","            Conv2d-3           [-1, 64, 32, 32]          36,928\n","              ReLU-4           [-1, 64, 32, 32]               0\n","         MaxPool2d-5           [-1, 64, 16, 16]               0\n","            Conv2d-6          [-1, 128, 16, 16]          73,856\n","              ReLU-7          [-1, 128, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]         147,584\n","              ReLU-9          [-1, 128, 16, 16]               0\n","        MaxPool2d-10            [-1, 128, 8, 8]               0\n","           Conv2d-11            [-1, 256, 8, 8]         295,168\n","             ReLU-12            [-1, 256, 8, 8]               0\n","           Conv2d-13            [-1, 256, 8, 8]         590,080\n","             ReLU-14            [-1, 256, 8, 8]               0\n","           Conv2d-15            [-1, 256, 8, 8]         590,080\n","             ReLU-16            [-1, 256, 8, 8]               0\n","        MaxPool2d-17            [-1, 256, 4, 4]               0\n","           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n","             ReLU-19            [-1, 512, 4, 4]               0\n","           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n","             ReLU-21            [-1, 512, 4, 4]               0\n","           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n","             ReLU-23            [-1, 512, 4, 4]               0\n","        MaxPool2d-24            [-1, 512, 2, 2]               0\n","           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n","             ReLU-26            [-1, 512, 2, 2]               0\n","           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n","             ReLU-28            [-1, 512, 2, 2]               0\n","           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n","             ReLU-30            [-1, 512, 2, 2]               0\n","        MaxPool2d-31            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n","           Linear-33                 [-1, 4096]     102,764,544\n","             ReLU-34                 [-1, 4096]               0\n","          Dropout-35                 [-1, 4096]               0\n","           Linear-36                 [-1, 4096]      16,781,312\n","             ReLU-37                 [-1, 4096]               0\n","          Dropout-38                 [-1, 4096]               0\n","           Linear-39                   [-1, 10]          40,970\n","================================================================\n","Total params: 134,301,514\n","Trainable params: 134,301,514\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 4.84\n","Params size (MB): 512.32\n","Estimated Total Size (MB): 517.17\n","----------------------------------------------------------------\n"]}],"source":["# Model 구현\n","class Custom_VGG(nn.Module):\n","    def __init__(self):\n","        super(Custom_VGG, self).__init__()\n","        ########################################## Complete This Code~!\n","        self.maxpool2d = nn.MaxPool2d(kernel_size=2)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.dropout = nn.Dropout()\n","\n","        self.conv1_1 = nn.Conv2d(3,64,3,padding=1)\n","        self.conv1_2 = nn.Conv2d(64,64,3,padding=1)\n","\n","        self.conv2_1 = nn.Conv2d(64,128,3,padding=1)\n","        self.conv2_2 = nn.Conv2d(128,128,3,padding=1)\n","\n","        self.conv3_1 = nn.Conv2d(128,256,3,padding=1)\n","        self.conv3_2 = nn.Conv2d(256,256,3,padding=1)\n","        self.conv3_3 = nn.Conv2d(256,256,3,padding=1)\n","\n","        self.conv4_1 = nn.Conv2d(256,512,3,padding=1)\n","        self.conv4_2 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv4_3 = nn.Conv2d(512,512,3,padding=1)\n","\n","        self.conv5_1 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv5_2 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv5_3 = nn.Conv2d(512,512,3,padding=1)\n","        self.adaptiveavgpool2d = nn.AdaptiveAvgPool2d((7,7))\n","\n","        self.fc1 = nn.Linear(512*7*7, 4096)\n","        self.fc2 = nn.Linear(4096, 4096)\n","        self.fc3 = nn.Linear(4096, 10)\n","        ########################################## Complete This Code~!\n","\n","    def forward(self, x): #(bs,3,32,32)\n","        ########################################## Complete This Code~!\n","        x = self.relu(self.conv1_1(x))\n","        x = self.relu(self.conv1_2(x))\n","        x = self.maxpool2d(x)\n","\n","        x = self.relu(self.conv2_1(x))\n","        x = self.relu(self.conv2_2(x))\n","        x = self.maxpool2d(x)\n","\n","        x = self.relu(self.conv3_1(x))\n","        x = self.relu(self.conv3_2(x))\n","        x = self.relu(self.conv3_3(x))\n","        x = self.maxpool2d(x)\n","\n","        x = self.relu(self.conv4_1(x))\n","        x = self.relu(self.conv4_2(x))\n","        x = self.relu(self.conv4_3(x))\n","        x = self.maxpool2d(x)\n","\n","        x = self.relu(self.conv5_1(x))\n","        x = self.relu(self.conv5_2(x))\n","        x = self.relu(self.conv5_3(x))\n","        x = self.maxpool2d(x) #(bs,512,1,1)\n","\n","        x = self.adaptiveavgpool2d(x) #(bs,512,7,7)\n","        x = x.view(-1,512*7*7) #(bs,512*7*7)\n","\n","        x = self.dropout(self.relu(self.fc1(x)))\n","        x = self.dropout(self.relu(self.fc2(x)))\n","        x = self.fc3(x)\n","        ########################################## Complete This Code~!\n","        return x\n","model = Custom_VGG().to(DEVICE)\n","summary(model, (3,32,32))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jkqHEqDBaoPQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703140405991,"user_tz":-540,"elapsed":2204,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}},"outputId":"bcb4f6ba-0bd2-430a-a0e7-1711f22e0ab3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","              ReLU-2           [-1, 64, 32, 32]               0\n","            Conv2d-3           [-1, 64, 32, 32]          36,928\n","              ReLU-4           [-1, 64, 32, 32]               0\n","         MaxPool2d-5           [-1, 64, 16, 16]               0\n","            Conv2d-6          [-1, 128, 16, 16]          73,856\n","              ReLU-7          [-1, 128, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]         147,584\n","              ReLU-9          [-1, 128, 16, 16]               0\n","        MaxPool2d-10            [-1, 128, 8, 8]               0\n","           Conv2d-11            [-1, 256, 8, 8]         295,168\n","             ReLU-12            [-1, 256, 8, 8]               0\n","           Conv2d-13            [-1, 256, 8, 8]         590,080\n","             ReLU-14            [-1, 256, 8, 8]               0\n","           Conv2d-15            [-1, 256, 8, 8]         590,080\n","             ReLU-16            [-1, 256, 8, 8]               0\n","        MaxPool2d-17            [-1, 256, 4, 4]               0\n","           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n","             ReLU-19            [-1, 512, 4, 4]               0\n","           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n","             ReLU-21            [-1, 512, 4, 4]               0\n","           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n","             ReLU-23            [-1, 512, 4, 4]               0\n","        MaxPool2d-24            [-1, 512, 2, 2]               0\n","           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n","             ReLU-26            [-1, 512, 2, 2]               0\n","           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n","             ReLU-28            [-1, 512, 2, 2]               0\n","           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n","             ReLU-30            [-1, 512, 2, 2]               0\n","        MaxPool2d-31            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n","           Linear-33                 [-1, 4096]     102,764,544\n","             ReLU-34                 [-1, 4096]               0\n","          Dropout-35                 [-1, 4096]               0\n","           Linear-36                 [-1, 4096]      16,781,312\n","             ReLU-37                 [-1, 4096]               0\n","          Dropout-38                 [-1, 4096]               0\n","           Linear-39                   [-1, 10]          40,970\n","================================================================\n","Total params: 134,301,514\n","Trainable params: 134,301,514\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 4.84\n","Params size (MB): 512.32\n","Estimated Total Size (MB): 517.17\n","----------------------------------------------------------------\n"]}],"source":["from torchvision import models\n","model_import = models.vgg16(pretrained=False, num_classes=10).to(DEVICE)\n","summary(model_import, (3, 32, 32))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"_b5IsHnKUquV","executionInfo":{"status":"ok","timestamp":1703140438860,"user_tz":-540,"elapsed":293,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}}},"outputs":[],"source":["# Optimizer 설정\n","optimizer = optim.Adam(model.parameters(), lr=LR)\n","# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"oy8oXE_mWARx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703141108066,"user_tz":-540,"elapsed":665718,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}},"outputId":"4daff8e5-3d0e-4b8c-8c93-62440f6d161f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.301144\n","Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.061522\n","Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.897231\n","Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.905950\n","[1] Test Loss: 1.7674, Accuracy: 26.62%\n","Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.841506\n","Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.749072\n","Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.432714\n","Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.523014\n","[2] Test Loss: 1.5038, Accuracy: 41.18%\n","Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.407584\n","Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.352085\n","Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.251646\n","Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.310710\n","[3] Test Loss: 1.2003, Accuracy: 56.10%\n","Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.957418\n","Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.231080\n","Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.022172\n","Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.074099\n","[4] Test Loss: 1.0053, Accuracy: 63.77%\n","Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.028640\n","Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.975768\n","Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.963509\n","Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.057127\n","[5] Test Loss: 0.9309, Accuracy: 67.35%\n","Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.989143\n","Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.649109\n","Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.824894\n","Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.782230\n","[6] Test Loss: 0.8000, Accuracy: 73.06%\n","Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.595322\n","Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.824382\n","Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.659504\n","Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.637037\n","[7] Test Loss: 0.7691, Accuracy: 73.70%\n","Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.357079\n","Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.578878\n","Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.620649\n","Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.497142\n","[8] Test Loss: 0.7628, Accuracy: 75.09%\n","Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.642812\n","Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.656852\n","Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.440707\n","Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.325292\n","[9] Test Loss: 0.7861, Accuracy: 75.37%\n","Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.316360\n","Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.541638\n","Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.515014\n","Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.427304\n","[10] Test Loss: 0.7285, Accuracy: 77.82%\n"]}],"source":["# Train 구현\n","def train_one_epoch(model, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(DEVICE), target.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.cross_entropy(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 200 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","# Evaluation 구현\n","def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(DEVICE), target.to(DEVICE)\n","            output = model(data)\n","\n","            # 배치 오차를 합산\n","            test_loss += F.cross_entropy(output, target,\n","                                         reduction='sum').item()\n","\n","            # 가장 높은 값을 가진 인덱스가 바로 예측값\n","            pred = output.max(1, keepdim=True)[1]\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy\n","\n","for epoch in range(1, EPOCHS + 1):\n","    train_one_epoch(model, train_loader, optimizer, epoch)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","\n","    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n","          epoch, test_loss, test_accuracy))"]},{"cell_type":"markdown","metadata":{"id":"JNxz2ARrE9Jp"},"source":["## Excercise 1) RESNET18 모델 구현\n","- [doc] (https://arxiv.org/pdf/1512.03385.pdf)\n","\n","![image.png](http://drive.google.com/uc?id=1GgHATI5PFF8-PlBdGp9vDra2maRqLybl)\n","\n","![image.png](http://drive.google.com/uc?id=1EYxIKJEI0rwIyW7ZZaFeZgJvol6Jb-XL)\n","\n","![image.png](http://drive.google.com/uc?id=17DgT11woHwXACEGOfvkVd8pYmxRI7vQl)\n","\n","![image.png](http://drive.google.com/uc?id=12reHf9xtapZrVBG4LlNbNGa37ZeFfUqk)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"5_IJRFtgHw02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703142336369,"user_tz":-540,"elapsed":2017,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}},"outputId":"a5bf4c2c-96db-4729-da6e-4e3025001306"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import transforms, datasets, utils\n","from torchsummary import summary\n","import matplotlib.pyplot as plt\n","\n","# DEVICE 설정\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","\n","# Parameter 설정\n","EPOCHS = 10\n","BATCH_SIZE = 64\n","LR = 0.01\n","\n","# Transform 설정\n","transform_CIFAR10 = transforms.Compose([\n","    # transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","])\n","\n","# Dataset 설정\n","train_dataset = datasets.CIFAR10(root = '../data',\n","                                         train = True,\n","                                         download = True,\n","                                         transform = transform_CIFAR10)\n","\n","test_dataset = datasets.CIFAR10(root = '../data',\n","                                train = False,\n","                                download = True,\n","                                transform = transform_CIFAR10)\n","\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                           batch_size = BATCH_SIZE,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","                                          batch_size = BATCH_SIZE,\n","                                          shuffle=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"1dykk5Om-cPG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703142338489,"user_tz":-540,"elapsed":337,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}},"outputId":"9c573b2f-2c12-479d-af45-b00f37e58320"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 14, 14]           9,472\n","       BatchNorm2d-2           [-1, 64, 14, 14]             128\n","              ReLU-3           [-1, 64, 14, 14]               0\n","         MaxPool2d-4             [-1, 64, 6, 6]               0\n","            Conv2d-5             [-1, 64, 6, 6]          36,928\n","       BatchNorm2d-6             [-1, 64, 6, 6]             128\n","              ReLU-7             [-1, 64, 6, 6]               0\n","            Conv2d-8             [-1, 64, 6, 6]          36,928\n","       BatchNorm2d-9             [-1, 64, 6, 6]             128\n","             ReLU-10             [-1, 64, 6, 6]               0\n","           Conv2d-11             [-1, 64, 6, 6]          36,928\n","      BatchNorm2d-12             [-1, 64, 6, 6]             128\n","             ReLU-13             [-1, 64, 6, 6]               0\n","           Conv2d-14             [-1, 64, 6, 6]          36,928\n","      BatchNorm2d-15             [-1, 64, 6, 6]             128\n","             ReLU-16             [-1, 64, 6, 6]               0\n","           Conv2d-17            [-1, 128, 3, 3]          73,856\n","      BatchNorm2d-18            [-1, 128, 3, 3]             256\n","             ReLU-19            [-1, 128, 3, 3]               0\n","           Conv2d-20            [-1, 128, 3, 3]         147,584\n","      BatchNorm2d-21            [-1, 128, 3, 3]             256\n","             ReLU-22            [-1, 128, 3, 3]               0\n","           Conv2d-23            [-1, 128, 3, 3]         147,584\n","      BatchNorm2d-24            [-1, 128, 3, 3]             256\n","             ReLU-25            [-1, 128, 3, 3]               0\n","           Conv2d-26            [-1, 128, 3, 3]         147,584\n","      BatchNorm2d-27            [-1, 128, 3, 3]             256\n","             ReLU-28            [-1, 128, 3, 3]               0\n","           Conv2d-29            [-1, 256, 2, 2]         295,168\n","      BatchNorm2d-30            [-1, 256, 2, 2]             512\n","             ReLU-31            [-1, 256, 2, 2]               0\n","           Conv2d-32            [-1, 256, 2, 2]         590,080\n","      BatchNorm2d-33            [-1, 256, 2, 2]             512\n","             ReLU-34            [-1, 256, 2, 2]               0\n","           Conv2d-35            [-1, 256, 2, 2]         590,080\n","      BatchNorm2d-36            [-1, 256, 2, 2]             512\n","             ReLU-37            [-1, 256, 2, 2]               0\n","           Conv2d-38            [-1, 256, 2, 2]         590,080\n","      BatchNorm2d-39            [-1, 256, 2, 2]             512\n","             ReLU-40            [-1, 256, 2, 2]               0\n","           Conv2d-41            [-1, 512, 1, 1]       1,180,160\n","      BatchNorm2d-42            [-1, 512, 1, 1]           1,024\n","             ReLU-43            [-1, 512, 1, 1]               0\n","           Conv2d-44            [-1, 512, 1, 1]       2,359,808\n","      BatchNorm2d-45            [-1, 512, 1, 1]           1,024\n","             ReLU-46            [-1, 512, 1, 1]               0\n","           Conv2d-47            [-1, 512, 1, 1]       2,359,808\n","      BatchNorm2d-48            [-1, 512, 1, 1]           1,024\n","             ReLU-49            [-1, 512, 1, 1]               0\n","           Conv2d-50            [-1, 512, 1, 1]       2,359,808\n","      BatchNorm2d-51            [-1, 512, 1, 1]           1,024\n","             ReLU-52            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-53            [-1, 512, 1, 1]               0\n","           Linear-54                   [-1, 10]           5,130\n","================================================================\n","Total params: 11,011,722\n","Trainable params: 11,011,722\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 0.77\n","Params size (MB): 42.01\n","Estimated Total Size (MB): 42.78\n","----------------------------------------------------------------\n"]}],"source":["# Model 구현\n","class Custom_RESNET(nn.Module):\n","    def __init__(self):\n","        super(Custom_RESNET, self).__init__()\n","        self.maxpool2d = nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=1)\n","        self.bn1 = nn.BatchNorm2d(num_features=64)\n","\n","        self.conv2_1 = nn.Conv2d(64,64,3,padding=1)\n","        self.conv2_2 = nn.Conv2d(64,64,3,padding=1)\n","        self.conv2_3 = nn.Conv2d(64,64,3,padding=1)\n","        self.conv2_4 = nn.Conv2d(64,64,3,padding=1)\n","        self.bn2_1 = nn.BatchNorm2d(num_features=64)\n","        self.bn2_2 = nn.BatchNorm2d(num_features=64)\n","        self.bn2_3 = nn.BatchNorm2d(num_features=64)\n","        self.bn2_4 = nn.BatchNorm2d(num_features=64)\n","\n","        self.conv3_1 = nn.Conv2d(64,128,3,padding=1, stride=2)\n","        self.conv3_2 = nn.Conv2d(128,128,3,padding=1)\n","        self.conv3_3 = nn.Conv2d(128,128,3,padding=1)\n","        self.conv3_4 = nn.Conv2d(128,128,3,padding=1)\n","        self.bn3_1 = nn.BatchNorm2d(num_features=128)\n","        self.bn3_2 = nn.BatchNorm2d(num_features=128)\n","        self.bn3_3 = nn.BatchNorm2d(num_features=128)\n","        self.bn3_4 = nn.BatchNorm2d(num_features=128)\n","\n","        self.conv4_1 = nn.Conv2d(128,256,3,padding=1, stride=2)\n","        self.conv4_2 = nn.Conv2d(256,256,3,padding=1)\n","        self.conv4_3 = nn.Conv2d(256,256,3,padding=1)\n","        self.conv4_4 = nn.Conv2d(256,256,3,padding=1)\n","        self.bn4_1 = nn.BatchNorm2d(num_features=256)\n","        self.bn4_2 = nn.BatchNorm2d(num_features=256)\n","        self.bn4_3 = nn.BatchNorm2d(num_features=256)\n","        self.bn4_4 = nn.BatchNorm2d(num_features=256)\n","\n","        self.conv5_1 = nn.Conv2d(256,512,3,padding=1, stride=2)\n","        self.conv5_2 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv5_3 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv5_4 = nn.Conv2d(512,512,3,padding=1)\n","        self.bn5_1 = nn.BatchNorm2d(num_features=512)\n","        self.bn5_2 = nn.BatchNorm2d(num_features=512)\n","        self.bn5_3 = nn.BatchNorm2d(num_features=512)\n","        self.bn5_4 = nn.BatchNorm2d(num_features=512)\n","\n","        self.adaptiveavgpool2d = nn.AdaptiveAvgPool2d(1)\n","\n","        self.fc = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        ########################################## Complete This Code~!\n","        x = self.relu(self.bn1(self.conv1(x)))\n","        x1 = self.maxpool2d(x)\n","\n","        x2_1 = self.relu(self.bn2_1(self.conv2_1(x1)))\n","        x2_2 = self.relu(self.bn2_2(self.conv2_2(x2_1))) + x1\n","        x2_3 = self.relu(self.bn2_3(self.conv2_3(x2_2)))\n","        x2_4 = self.relu(self.bn2_4(self.conv2_4(x2_3))) + x2_2\n","\n","        x3_1 = self.relu(self.bn3_1(self.conv3_1(x2_4)))\n","        x3_2 = self.relu(self.bn3_2(self.conv3_2(x3_1))) #+ x2_4\n","        x3_3 = self.relu(self.bn3_3(self.conv3_3(x3_2)))\n","        x3_4 = self.relu(self.bn3_4(self.conv3_4(x3_3))) + x3_2\n","\n","        x4_1 = self.relu(self.bn4_1(self.conv4_1(x3_4)))\n","        x4_2 = self.relu(self.bn4_2(self.conv4_2(x4_1))) #+ x3_4\n","        x4_3 = self.relu(self.bn4_3(self.conv4_3(x4_2)))\n","        x4_4 = self.relu(self.bn4_4(self.conv4_4(x4_3))) + x4_2\n","\n","        x5_1 = self.relu(self.bn5_1(self.conv5_1(x4_4)))\n","        x5_2 = self.relu(self.bn5_2(self.conv5_2(x5_1))) #+ x4_4\n","        x5_3 = self.relu(self.bn5_3(self.conv5_3(x5_2)))\n","        x5_4 = self.relu(self.bn5_4(self.conv5_4(x5_3))) + x5_2\n","        ########################################## Complete This Code~!\n","\n","        x = self.adaptiveavgpool2d(x5_4)\n","        x = x.view(-1,512)\n","        x = self.fc(x)\n","        return x\n","\n","model = Custom_RESNET().to(DEVICE)\n","summary(model, (3, 32, 32))"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"YJq3fJZHHw7_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703142343523,"user_tz":-540,"elapsed":343,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}},"outputId":"5856630b-f8b8-467e-e3eb-5489d2d88d23"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 16, 16]           9,408\n","       BatchNorm2d-2           [-1, 64, 16, 16]             128\n","              ReLU-3           [-1, 64, 16, 16]               0\n","         MaxPool2d-4             [-1, 64, 8, 8]               0\n","            Conv2d-5             [-1, 64, 8, 8]          36,864\n","       BatchNorm2d-6             [-1, 64, 8, 8]             128\n","              ReLU-7             [-1, 64, 8, 8]               0\n","            Conv2d-8             [-1, 64, 8, 8]          36,864\n","       BatchNorm2d-9             [-1, 64, 8, 8]             128\n","             ReLU-10             [-1, 64, 8, 8]               0\n","       BasicBlock-11             [-1, 64, 8, 8]               0\n","           Conv2d-12             [-1, 64, 8, 8]          36,864\n","      BatchNorm2d-13             [-1, 64, 8, 8]             128\n","             ReLU-14             [-1, 64, 8, 8]               0\n","           Conv2d-15             [-1, 64, 8, 8]          36,864\n","      BatchNorm2d-16             [-1, 64, 8, 8]             128\n","             ReLU-17             [-1, 64, 8, 8]               0\n","       BasicBlock-18             [-1, 64, 8, 8]               0\n","           Conv2d-19            [-1, 128, 4, 4]          73,728\n","      BatchNorm2d-20            [-1, 128, 4, 4]             256\n","             ReLU-21            [-1, 128, 4, 4]               0\n","           Conv2d-22            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-23            [-1, 128, 4, 4]             256\n","           Conv2d-24            [-1, 128, 4, 4]           8,192\n","      BatchNorm2d-25            [-1, 128, 4, 4]             256\n","             ReLU-26            [-1, 128, 4, 4]               0\n","       BasicBlock-27            [-1, 128, 4, 4]               0\n","           Conv2d-28            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-29            [-1, 128, 4, 4]             256\n","             ReLU-30            [-1, 128, 4, 4]               0\n","           Conv2d-31            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-32            [-1, 128, 4, 4]             256\n","             ReLU-33            [-1, 128, 4, 4]               0\n","       BasicBlock-34            [-1, 128, 4, 4]               0\n","           Conv2d-35            [-1, 256, 2, 2]         294,912\n","      BatchNorm2d-36            [-1, 256, 2, 2]             512\n","             ReLU-37            [-1, 256, 2, 2]               0\n","           Conv2d-38            [-1, 256, 2, 2]         589,824\n","      BatchNorm2d-39            [-1, 256, 2, 2]             512\n","           Conv2d-40            [-1, 256, 2, 2]          32,768\n","      BatchNorm2d-41            [-1, 256, 2, 2]             512\n","             ReLU-42            [-1, 256, 2, 2]               0\n","       BasicBlock-43            [-1, 256, 2, 2]               0\n","           Conv2d-44            [-1, 256, 2, 2]         589,824\n","      BatchNorm2d-45            [-1, 256, 2, 2]             512\n","             ReLU-46            [-1, 256, 2, 2]               0\n","           Conv2d-47            [-1, 256, 2, 2]         589,824\n","      BatchNorm2d-48            [-1, 256, 2, 2]             512\n","             ReLU-49            [-1, 256, 2, 2]               0\n","       BasicBlock-50            [-1, 256, 2, 2]               0\n","           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n","      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n","             ReLU-53            [-1, 512, 1, 1]               0\n","           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n","      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n","           Conv2d-56            [-1, 512, 1, 1]         131,072\n","      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n","             ReLU-58            [-1, 512, 1, 1]               0\n","       BasicBlock-59            [-1, 512, 1, 1]               0\n","           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n","      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n","             ReLU-62            [-1, 512, 1, 1]               0\n","           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n","      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n","             ReLU-65            [-1, 512, 1, 1]               0\n","       BasicBlock-66            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n","           Linear-68                   [-1, 10]           5,130\n","================================================================\n","Total params: 11,181,642\n","Trainable params: 11,181,642\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 1.29\n","Params size (MB): 42.65\n","Estimated Total Size (MB): 43.95\n","----------------------------------------------------------------\n"]}],"source":["from torchvision import models\n","model_import = models.resnet18(pretrained=False, num_classes=10).to(DEVICE)\n","summary(model_import, (3, 32, 32))"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"pUam0mfLavpg","executionInfo":{"status":"ok","timestamp":1703142346930,"user_tz":-540,"elapsed":2,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}}},"outputs":[],"source":["# Model, Optimizer 설정\n","optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.5)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"GM0Tm7RJHzv-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703142596938,"user_tz":-540,"elapsed":248056,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"}},"outputId":"91381a62-b5c4-4c0d-e079-54ad847c2107"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.337573\n","Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.539466\n","Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.010749\n","Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.100583\n","[1] Test Loss: 1.2337, Accuracy: 56.22%\n","Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.922772\n","Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.050283\n","Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.512174\n","Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.162385\n","[2] Test Loss: 1.1216, Accuracy: 60.88%\n","Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.968262\n","Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.081725\n","Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.859997\n","Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.803694\n","[3] Test Loss: 0.9373, Accuracy: 67.33%\n","Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.676159\n","Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.970080\n","Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.790411\n","Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.872101\n","[4] Test Loss: 0.9459, Accuracy: 67.47%\n","Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.564553\n","Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.846611\n","Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.847725\n","Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.575763\n","[5] Test Loss: 0.9819, Accuracy: 67.25%\n","Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.654981\n","Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.445972\n","Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.570193\n","Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.496116\n","[6] Test Loss: 1.0002, Accuracy: 67.16%\n","Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.469814\n","Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.351943\n","Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.549068\n","Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.450610\n","[7] Test Loss: 0.9056, Accuracy: 70.22%\n","Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.416498\n","Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.860243\n","Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.297054\n","Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.355160\n","[8] Test Loss: 0.9490, Accuracy: 69.48%\n","Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.469102\n","Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.376641\n","Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.344115\n","Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.383784\n","[9] Test Loss: 0.9633, Accuracy: 71.32%\n","Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.284277\n","Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.243640\n","Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.417687\n","Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.433310\n","[10] Test Loss: 0.9687, Accuracy: 71.21%\n"]}],"source":["# Train 구현\n","def train_one_epoch(model, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(DEVICE), target.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.cross_entropy(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 200 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","# Evaluation 구현\n","def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(DEVICE), target.to(DEVICE)\n","            output = model(data)\n","\n","            # 배치 오차를 합산\n","            test_loss += F.cross_entropy(output, target,\n","                                         reduction='sum').item()\n","\n","            # 가장 높은 값을 가진 인덱스가 바로 예측값\n","            pred = output.max(1, keepdim=True)[1]\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy\n","\n","for epoch in range(1, EPOCHS + 1):\n","    train_one_epoch(model, train_loader, optimizer, epoch)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","\n","    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n","          epoch, test_loss, test_accuracy))"]},{"cell_type":"code","source":[],"metadata":{"id":"JuAZvInULZiV"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1UpQVm6iH6RDOKjU-fl5gTfDsc80fOOxZ","timestamp":1627397450310}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}