{"cells":[{"cell_type":"markdown","metadata":{"id":"D9UUcbMe5uHd"},"source":["# Day4-1 : VGG, RESNET model simple Implementation with CIFAR10 dataset (45 min)\n","####  이번 실습에서는 CNN 아키텍쳐 중 가장 대표적인 VGG과 RESNET 모델을 간단히 구현해보고 CIFAR-10 데이터셋에 대해 학습 및 Inference를 해볼 계획입니다."]},{"cell_type":"markdown","metadata":{"id":"pMY3CPV4ebV2"},"source":["## Example 1) VGG16 모델 구현 (20min)\n","- [doc] (https://arxiv.org/pdf/1409.1556.pdf)\n","\n","![image.png](http://drive.google.com/uc?id=1E6MVIcFCsImwWQGOhC-8KUQqAe2W_I28)\n","\n","![image.png](http://drive.google.com/uc?id=1jT9jhqMzEaHoma5xvro5jf6PFOq7FlLJ)\n","\n","![image.png](http://drive.google.com/uc?id=17DgT11woHwXACEGOfvkVd8pYmxRI7vQl)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29609,"status":"ok","timestamp":1703044644285,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"},"user_tz":-540},"id":"jbce4wfMMTqv","outputId":"4029b08e-4b1b-4ab8-c674-d7717b8d844f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:13<00:00, 12346423.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/cifar-10-python.tar.gz to ../data\n","Files already downloaded and verified\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import transforms, datasets, utils\n","from torchsummary import summary\n","import matplotlib.pyplot as plt\n","\n","# DEVICE 설정\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","\n","# Parameter 설정\n","EPOCHS = 10\n","BATCH_SIZE = 64\n","LR = 0.0001\n","\n","# Transform 설정\n","transform_CIFAR10 = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","])\n","\n","# Dataset 설정\n","train_dataset = datasets.CIFAR10(root = '../data',\n","                                         train = True,\n","                                         download = True,\n","                                         transform = transform_CIFAR10)\n","\n","test_dataset = datasets.CIFAR10(root = '../data',\n","                                train = False,\n","                                download = True,\n","                                transform = transform_CIFAR10)\n","\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                           batch_size = BATCH_SIZE,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","                                          batch_size = BATCH_SIZE,\n","                                          shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3135,"status":"ok","timestamp":1703044652116,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"},"user_tz":-540},"id":"_JeDJmfNuN0k","outputId":"237e3f39-641f-428c-936a-0fb072003dd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","              ReLU-2           [-1, 64, 32, 32]               0\n","            Conv2d-3           [-1, 64, 32, 32]          36,928\n","              ReLU-4           [-1, 64, 32, 32]               0\n","         MaxPool2d-5           [-1, 64, 16, 16]               0\n","            Conv2d-6          [-1, 128, 16, 16]          73,856\n","              ReLU-7          [-1, 128, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]         147,584\n","              ReLU-9          [-1, 128, 16, 16]               0\n","        MaxPool2d-10            [-1, 128, 8, 8]               0\n","           Conv2d-11            [-1, 256, 8, 8]         295,168\n","             ReLU-12            [-1, 256, 8, 8]               0\n","           Conv2d-13            [-1, 256, 8, 8]         590,080\n","             ReLU-14            [-1, 256, 8, 8]               0\n","           Conv2d-15            [-1, 256, 8, 8]         590,080\n","             ReLU-16            [-1, 256, 8, 8]               0\n","        MaxPool2d-17            [-1, 256, 4, 4]               0\n","           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n","             ReLU-19            [-1, 512, 4, 4]               0\n","           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n","             ReLU-21            [-1, 512, 4, 4]               0\n","           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n","             ReLU-23            [-1, 512, 4, 4]               0\n","        MaxPool2d-24            [-1, 512, 2, 2]               0\n","           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n","             ReLU-26            [-1, 512, 2, 2]               0\n","           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n","             ReLU-28            [-1, 512, 2, 2]               0\n","           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n","             ReLU-30            [-1, 512, 2, 2]               0\n","        MaxPool2d-31            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n","           Linear-33                 [-1, 4096]     102,764,544\n","             ReLU-34                 [-1, 4096]               0\n","          Dropout-35                 [-1, 4096]               0\n","           Linear-36                 [-1, 4096]      16,781,312\n","             ReLU-37                 [-1, 4096]               0\n","          Dropout-38                 [-1, 4096]               0\n","           Linear-39                   [-1, 10]          40,970\n","================================================================\n","Total params: 134,301,514\n","Trainable params: 134,301,514\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 4.84\n","Params size (MB): 512.32\n","Estimated Total Size (MB): 517.17\n","----------------------------------------------------------------\n"]}],"source":["# Model 구현\n","class Custom_VGG(nn.Module):\n","    def __init__(self):\n","        super(Custom_VGG, self).__init__()\n","        ########################################## Complete This Code~!\n","        self.maxpool2d = nn.MaxPool2d(kernel_size=2)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.dropout = nn.Dropout()\n","\n","        self.conv1_1 = nn.Conv2d(3,64,3,padding=1)\n","        self.conv1_2 = nn.Conv2d(64,64,3,padding=1)\n","\n","        self.conv2_1 = nn.Conv2d(64,128,3,padding=1)\n","        self.conv2_2 = nn.Conv2d(128,128,3,padding=1)\n","\n","        self.conv3_1 = nn.Conv2d(128,256,3,padding=1)\n","        self.conv3_2 = nn.Conv2d(256,256,3,padding=1)\n","        self.conv3_3 = nn.Conv2d(256,256,3,padding=1)\n","\n","        self.conv4_1 = nn.Conv2d(256,512,3,padding=1)\n","        self.conv4_2 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv4_3 = nn.Conv2d(512,512,3,padding=1)\n","\n","        self.conv5_1 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv5_2 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv5_3 = nn.Conv2d(512,512,3,padding=1)\n","        self.adaptiveavgpool2d = nn.AdaptiveAvgPool2d((7,7))\n","\n","        self.fc1 = nn.Linear(512*7*7, 4096)\n","        self.fc2 = nn.Linear(4096, 4096)\n","        self.fc3 = nn.Linear(4096, 10)\n","        ########################################## Complete This Code~!\n","\n","    def forward(self, x): #(bs,3,32,32)\n","        ########################################## Complete This Code~!\n","        x = self.relu(self.conv1_1(x))\n","        x = self.relu(self.conv1_2(x))\n","        x = self.maxpool2d(x)\n","\n","        x = self.relu(self.conv2_1(x))\n","        x = self.relu(self.conv2_2(x))\n","        x = self.maxpool2d(x)\n","\n","        x = self.relu(self.conv3_1(x))\n","        x = self.relu(self.conv3_2(x))\n","        x = self.relu(self.conv3_3(x))\n","        x = self.maxpool2d(x)\n","\n","        x = self.relu(self.conv4_1(x))\n","        x = self.relu(self.conv4_2(x))\n","        x = self.relu(self.conv4_3(x))\n","        x = self.maxpool2d(x)\n","\n","        x = self.relu(self.conv5_1(x))\n","        x = self.relu(self.conv5_2(x))\n","        x = self.relu(self.conv5_3(x))\n","        x = self.maxpool2d(x) #(bs,512,1,1)\n","\n","        x = self.adaptiveavgpool2d(x) #(bs,512,7,7)\n","        x = x.view(-1,512*7*7) #(bs,512*7*7)\n","\n","        x = self.dropout(self.relu(self.fc1(x)))\n","        x = self.dropout(self.relu(self.fc2(x)))\n","        x = self.fc3(x)\n","        ########################################## Complete This Code~!\n","        return x\n","model = Custom_VGG().to(DEVICE)\n","summary(model, (3,32,32))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2898,"status":"ok","timestamp":1702978537611,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"},"user_tz":-540},"id":"jkqHEqDBaoPQ","outputId":"64f269f2-0d10-4587-d2a6-f18fdc634fb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","              ReLU-2           [-1, 64, 32, 32]               0\n","            Conv2d-3           [-1, 64, 32, 32]          36,928\n","              ReLU-4           [-1, 64, 32, 32]               0\n","         MaxPool2d-5           [-1, 64, 16, 16]               0\n","            Conv2d-6          [-1, 128, 16, 16]          73,856\n","              ReLU-7          [-1, 128, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]         147,584\n","              ReLU-9          [-1, 128, 16, 16]               0\n","        MaxPool2d-10            [-1, 128, 8, 8]               0\n","           Conv2d-11            [-1, 256, 8, 8]         295,168\n","             ReLU-12            [-1, 256, 8, 8]               0\n","           Conv2d-13            [-1, 256, 8, 8]         590,080\n","             ReLU-14            [-1, 256, 8, 8]               0\n","           Conv2d-15            [-1, 256, 8, 8]         590,080\n","             ReLU-16            [-1, 256, 8, 8]               0\n","        MaxPool2d-17            [-1, 256, 4, 4]               0\n","           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n","             ReLU-19            [-1, 512, 4, 4]               0\n","           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n","             ReLU-21            [-1, 512, 4, 4]               0\n","           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n","             ReLU-23            [-1, 512, 4, 4]               0\n","        MaxPool2d-24            [-1, 512, 2, 2]               0\n","           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n","             ReLU-26            [-1, 512, 2, 2]               0\n","           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n","             ReLU-28            [-1, 512, 2, 2]               0\n","           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n","             ReLU-30            [-1, 512, 2, 2]               0\n","        MaxPool2d-31            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n","           Linear-33                 [-1, 4096]     102,764,544\n","             ReLU-34                 [-1, 4096]               0\n","          Dropout-35                 [-1, 4096]               0\n","           Linear-36                 [-1, 4096]      16,781,312\n","             ReLU-37                 [-1, 4096]               0\n","          Dropout-38                 [-1, 4096]               0\n","           Linear-39                   [-1, 10]          40,970\n","================================================================\n","Total params: 134,301,514\n","Trainable params: 134,301,514\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 4.84\n","Params size (MB): 512.32\n","Estimated Total Size (MB): 517.17\n","----------------------------------------------------------------\n"]}],"source":["from torchvision import models\n","model_import = models.vgg16(pretrained=False, num_classes=10).to(DEVICE)\n","summary(model_import, (3, 32, 32))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_b5IsHnKUquV"},"outputs":[],"source":["# Optimizer 설정\n","optimizer = optim.Adam(model.parameters(), lr=LR)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":630},"executionInfo":{"elapsed":152681,"status":"error","timestamp":1702978493105,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"},"user_tz":-540},"id":"oy8oXE_mWARx","outputId":"423de273-d98d-47ea-ad7a-1c7e669ce607"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.303934\n","Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.301980\n","Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.305108\n","Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.304670\n","[1] Test Loss: 2.3028, Accuracy: 10.00%\n","Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.303710\n","Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.307111\n","Train Epoch: 2 [25600/50000 (51%)]\tLoss: 2.304796\n","Train Epoch: 2 [38400/50000 (77%)]\tLoss: 2.302107\n","[2] Test Loss: 2.3026, Accuracy: 10.00%\n","Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.301913\n","Train Epoch: 3 [12800/50000 (26%)]\tLoss: 2.301207\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-bd9929b8c5c5>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-bd9929b8c5c5>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-c1379c4c0944>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m########################################## Complete This Code~!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Train 구현\n","def train_one_epoch(model, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(DEVICE), target.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.cross_entropy(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 200 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","# Evaluation 구현\n","def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(DEVICE), target.to(DEVICE)\n","            output = model(data)\n","\n","            # 배치 오차를 합산\n","            test_loss += F.cross_entropy(output, target,\n","                                         reduction='sum').item()\n","\n","            # 가장 높은 값을 가진 인덱스가 바로 예측값\n","            pred = output.max(1, keepdim=True)[1]\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy\n","\n","for epoch in range(1, EPOCHS + 1):\n","    train_one_epoch(model_import, train_loader, optimizer, epoch)\n","    test_loss, test_accuracy = evaluate(model_import, test_loader)\n","\n","    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n","          epoch, test_loss, test_accuracy))"]},{"cell_type":"markdown","metadata":{"id":"JNxz2ARrE9Jp"},"source":["## Excercise 1) RESNET18 모델 구현(25min[Explain:5min/Exercise:10min/Explain:10min)]\n","- [doc] (https://arxiv.org/pdf/1512.03385.pdf)\n","\n","![image.png](http://drive.google.com/uc?id=1GgHATI5PFF8-PlBdGp9vDra2maRqLybl)\n","\n","![image.png](http://drive.google.com/uc?id=1EYxIKJEI0rwIyW7ZZaFeZgJvol6Jb-XL)\n","\n","![image.png](http://drive.google.com/uc?id=17DgT11woHwXACEGOfvkVd8pYmxRI7vQl)\n","\n","![image.png](http://drive.google.com/uc?id=12reHf9xtapZrVBG4LlNbNGa37ZeFfUqk)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2040,"status":"ok","timestamp":1702979454945,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"},"user_tz":-540},"id":"5_IJRFtgHw02","outputId":"2d0a26fe-c41d-4c38-a5ca-28925102998a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import transforms, datasets, utils\n","from torchsummary import summary\n","import matplotlib.pyplot as plt\n","\n","# DEVICE 설정\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","\n","# Parameter 설정\n","EPOCHS = 10\n","BATCH_SIZE = 64\n","LR = 0.01\n","\n","# Transform 설정\n","transform_CIFAR10 = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","])\n","\n","# Dataset 설정\n","train_dataset = datasets.CIFAR10(root = '../data',\n","                                         train = True,\n","                                         download = True,\n","                                         transform = transform_CIFAR10)\n","\n","test_dataset = datasets.CIFAR10(root = '../data',\n","                                train = False,\n","                                download = True,\n","                                transform = transform_CIFAR10)\n","\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                           batch_size = BATCH_SIZE,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","                                          batch_size = BATCH_SIZE,\n","                                          shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1702979454945,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"},"user_tz":-540},"id":"1dykk5Om-cPG","outputId":"78385504-8d42-4c52-8eea-1841f986a5fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 14, 14]           9,472\n","       BatchNorm2d-2           [-1, 64, 14, 14]             128\n","              ReLU-3           [-1, 64, 14, 14]               0\n","         MaxPool2d-4             [-1, 64, 6, 6]               0\n","            Conv2d-5             [-1, 64, 6, 6]          36,928\n","       BatchNorm2d-6             [-1, 64, 6, 6]             128\n","              ReLU-7             [-1, 64, 6, 6]               0\n","            Conv2d-8             [-1, 64, 6, 6]          36,928\n","       BatchNorm2d-9             [-1, 64, 6, 6]             128\n","             ReLU-10             [-1, 64, 6, 6]               0\n","           Conv2d-11             [-1, 64, 6, 6]          36,928\n","      BatchNorm2d-12             [-1, 64, 6, 6]             128\n","             ReLU-13             [-1, 64, 6, 6]               0\n","           Conv2d-14             [-1, 64, 6, 6]          36,928\n","      BatchNorm2d-15             [-1, 64, 6, 6]             128\n","             ReLU-16             [-1, 64, 6, 6]               0\n","           Conv2d-17            [-1, 128, 3, 3]          73,856\n","      BatchNorm2d-18            [-1, 128, 3, 3]             256\n","             ReLU-19            [-1, 128, 3, 3]               0\n","           Conv2d-20            [-1, 128, 3, 3]         147,584\n","      BatchNorm2d-21            [-1, 128, 3, 3]             256\n","             ReLU-22            [-1, 128, 3, 3]               0\n","           Conv2d-23            [-1, 128, 3, 3]         147,584\n","      BatchNorm2d-24            [-1, 128, 3, 3]             256\n","             ReLU-25            [-1, 128, 3, 3]               0\n","           Conv2d-26            [-1, 128, 3, 3]         147,584\n","      BatchNorm2d-27            [-1, 128, 3, 3]             256\n","             ReLU-28            [-1, 128, 3, 3]               0\n","           Conv2d-29            [-1, 256, 2, 2]         295,168\n","      BatchNorm2d-30            [-1, 256, 2, 2]             512\n","             ReLU-31            [-1, 256, 2, 2]               0\n","           Conv2d-32            [-1, 256, 2, 2]         590,080\n","      BatchNorm2d-33            [-1, 256, 2, 2]             512\n","             ReLU-34            [-1, 256, 2, 2]               0\n","           Conv2d-35            [-1, 256, 2, 2]         590,080\n","      BatchNorm2d-36            [-1, 256, 2, 2]             512\n","             ReLU-37            [-1, 256, 2, 2]               0\n","           Conv2d-38            [-1, 256, 2, 2]         590,080\n","      BatchNorm2d-39            [-1, 256, 2, 2]             512\n","             ReLU-40            [-1, 256, 2, 2]               0\n","           Conv2d-41            [-1, 512, 1, 1]       1,180,160\n","      BatchNorm2d-42            [-1, 512, 1, 1]           1,024\n","             ReLU-43            [-1, 512, 1, 1]               0\n","           Conv2d-44            [-1, 512, 1, 1]       2,359,808\n","      BatchNorm2d-45            [-1, 512, 1, 1]           1,024\n","             ReLU-46            [-1, 512, 1, 1]               0\n","           Conv2d-47            [-1, 512, 1, 1]       2,359,808\n","      BatchNorm2d-48            [-1, 512, 1, 1]           1,024\n","             ReLU-49            [-1, 512, 1, 1]               0\n","           Conv2d-50            [-1, 512, 1, 1]       2,359,808\n","      BatchNorm2d-51            [-1, 512, 1, 1]           1,024\n","             ReLU-52            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-53            [-1, 512, 1, 1]               0\n","           Linear-54                   [-1, 10]           5,130\n","================================================================\n","Total params: 11,011,722\n","Trainable params: 11,011,722\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 0.77\n","Params size (MB): 42.01\n","Estimated Total Size (MB): 42.78\n","----------------------------------------------------------------\n"]}],"source":["# Model 구현\n","class Custom_RESNET(nn.Module):\n","    def __init__(self):\n","        super(Custom_RESNET, self).__init__()\n","        self.maxpool2d = nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=1)\n","        self.bn1 = nn.BatchNorm2d(num_features=64)\n","\n","        self.conv2_1 = nn.Conv2d(64,64,3,padding=1)\n","        self.conv2_2 = nn.Conv2d(64,64,3,padding=1)\n","        self.conv2_3 = nn.Conv2d(64,64,3,padding=1)\n","        self.conv2_4 = nn.Conv2d(64,64,3,padding=1)\n","        self.bn2_1 = nn.BatchNorm2d(num_features=64)\n","        self.bn2_2 = nn.BatchNorm2d(num_features=64)\n","        self.bn2_3 = nn.BatchNorm2d(num_features=64)\n","        self.bn2_4 = nn.BatchNorm2d(num_features=64)\n","\n","        self.conv3_1 = nn.Conv2d(64,128,3,padding=1, stride=2)\n","        self.conv3_2 = nn.Conv2d(128,128,3,padding=1)\n","        self.conv3_3 = nn.Conv2d(128,128,3,padding=1)\n","        self.conv3_4 = nn.Conv2d(128,128,3,padding=1)\n","        self.bn3_1 = nn.BatchNorm2d(num_features=128)\n","        self.bn3_2 = nn.BatchNorm2d(num_features=128)\n","        self.bn3_3 = nn.BatchNorm2d(num_features=128)\n","        self.bn3_4 = nn.BatchNorm2d(num_features=128)\n","\n","        self.conv4_1 = nn.Conv2d(128,256,3,padding=1, stride=2)\n","        self.conv4_2 = nn.Conv2d(256,256,3,padding=1)\n","        self.conv4_3 = nn.Conv2d(256,256,3,padding=1)\n","        self.conv4_4 = nn.Conv2d(256,256,3,padding=1)\n","        self.bn4_1 = nn.BatchNorm2d(num_features=256)\n","        self.bn4_2 = nn.BatchNorm2d(num_features=256)\n","        self.bn4_3 = nn.BatchNorm2d(num_features=256)\n","        self.bn4_4 = nn.BatchNorm2d(num_features=256)\n","\n","        self.conv5_1 = nn.Conv2d(256,512,3,padding=1, stride=2)\n","        self.conv5_2 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv5_3 = nn.Conv2d(512,512,3,padding=1)\n","        self.conv5_4 = nn.Conv2d(512,512,3,padding=1)\n","        self.bn5_1 = nn.BatchNorm2d(num_features=512)\n","        self.bn5_2 = nn.BatchNorm2d(num_features=512)\n","        self.bn5_3 = nn.BatchNorm2d(num_features=512)\n","        self.bn5_4 = nn.BatchNorm2d(num_features=512)\n","\n","        self.adaptiveavgpool2d = nn.AdaptiveAvgPool2d(1)\n","\n","        self.fc = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        ########################################## Complete This Code~!\n","        x = self.relu(self.bn1(self.conv1(x)))\n","        x1 = self.maxpool2d(x)\n","\n","        x2_1 = self.relu(self.bn2_1(self.conv2_1(x1)))\n","        x2_2 = self.relu(self.bn2_2(self.conv2_2(x2_1))) + x1\n","        x2_3 = self.relu(self.bn2_3(self.conv2_3(x2_2)))\n","        x2_4 = self.relu(self.bn2_4(self.conv2_4(x2_3))) + x2_2\n","\n","        x3_1 = self.relu(self.bn3_1(self.conv3_1(x2_4)))\n","        x3_2 = self.relu(self.bn3_2(self.conv3_2(x3_1))) #+ x2_4\n","        x3_3 = self.relu(self.bn3_3(self.conv3_3(x3_2)))\n","        x3_4 = self.relu(self.bn3_4(self.conv3_4(x3_3))) + x3_2\n","\n","        x4_1 = self.relu(self.bn4_1(self.conv4_1(x3_4)))\n","        x4_2 = self.relu(self.bn4_2(self.conv4_2(x4_1))) #+ x3_4\n","        x4_3 = self.relu(self.bn4_3(self.conv4_3(x4_2)))\n","        x4_4 = self.relu(self.bn4_4(self.conv4_4(x4_3))) + x4_2\n","\n","        x5_1 = self.relu(self.bn5_1(self.conv5_1(x4_4)))\n","        x5_2 = self.relu(self.bn5_2(self.conv5_2(x5_1))) #+ x4_4\n","        x5_3 = self.relu(self.bn5_3(self.conv5_3(x5_2)))\n","        x5_4 = self.relu(self.bn5_4(self.conv5_4(x5_3))) + x5_2\n","        ########################################## Complete This Code~!\n","\n","        x = self.adaptiveavgpool2d(x5_4)\n","        x = x.view(-1,512)\n","        x = self.fc(x)\n","        return x\n","\n","model = Custom_RESNET().to(DEVICE)\n","summary(model, (3, 32, 32))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702979454945,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"},"user_tz":-540},"id":"YJq3fJZHHw7_","outputId":"22d4c3d5-2141-4759-daf9-e0d883424cd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 16, 16]           9,408\n","       BatchNorm2d-2           [-1, 64, 16, 16]             128\n","              ReLU-3           [-1, 64, 16, 16]               0\n","         MaxPool2d-4             [-1, 64, 8, 8]               0\n","            Conv2d-5             [-1, 64, 8, 8]          36,864\n","       BatchNorm2d-6             [-1, 64, 8, 8]             128\n","              ReLU-7             [-1, 64, 8, 8]               0\n","            Conv2d-8             [-1, 64, 8, 8]          36,864\n","       BatchNorm2d-9             [-1, 64, 8, 8]             128\n","             ReLU-10             [-1, 64, 8, 8]               0\n","       BasicBlock-11             [-1, 64, 8, 8]               0\n","           Conv2d-12             [-1, 64, 8, 8]          36,864\n","      BatchNorm2d-13             [-1, 64, 8, 8]             128\n","             ReLU-14             [-1, 64, 8, 8]               0\n","           Conv2d-15             [-1, 64, 8, 8]          36,864\n","      BatchNorm2d-16             [-1, 64, 8, 8]             128\n","             ReLU-17             [-1, 64, 8, 8]               0\n","       BasicBlock-18             [-1, 64, 8, 8]               0\n","           Conv2d-19            [-1, 128, 4, 4]          73,728\n","      BatchNorm2d-20            [-1, 128, 4, 4]             256\n","             ReLU-21            [-1, 128, 4, 4]               0\n","           Conv2d-22            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-23            [-1, 128, 4, 4]             256\n","           Conv2d-24            [-1, 128, 4, 4]           8,192\n","      BatchNorm2d-25            [-1, 128, 4, 4]             256\n","             ReLU-26            [-1, 128, 4, 4]               0\n","       BasicBlock-27            [-1, 128, 4, 4]               0\n","           Conv2d-28            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-29            [-1, 128, 4, 4]             256\n","             ReLU-30            [-1, 128, 4, 4]               0\n","           Conv2d-31            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-32            [-1, 128, 4, 4]             256\n","             ReLU-33            [-1, 128, 4, 4]               0\n","       BasicBlock-34            [-1, 128, 4, 4]               0\n","           Conv2d-35            [-1, 256, 2, 2]         294,912\n","      BatchNorm2d-36            [-1, 256, 2, 2]             512\n","             ReLU-37            [-1, 256, 2, 2]               0\n","           Conv2d-38            [-1, 256, 2, 2]         589,824\n","      BatchNorm2d-39            [-1, 256, 2, 2]             512\n","           Conv2d-40            [-1, 256, 2, 2]          32,768\n","      BatchNorm2d-41            [-1, 256, 2, 2]             512\n","             ReLU-42            [-1, 256, 2, 2]               0\n","       BasicBlock-43            [-1, 256, 2, 2]               0\n","           Conv2d-44            [-1, 256, 2, 2]         589,824\n","      BatchNorm2d-45            [-1, 256, 2, 2]             512\n","             ReLU-46            [-1, 256, 2, 2]               0\n","           Conv2d-47            [-1, 256, 2, 2]         589,824\n","      BatchNorm2d-48            [-1, 256, 2, 2]             512\n","             ReLU-49            [-1, 256, 2, 2]               0\n","       BasicBlock-50            [-1, 256, 2, 2]               0\n","           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n","      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n","             ReLU-53            [-1, 512, 1, 1]               0\n","           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n","      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n","           Conv2d-56            [-1, 512, 1, 1]         131,072\n","      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n","             ReLU-58            [-1, 512, 1, 1]               0\n","       BasicBlock-59            [-1, 512, 1, 1]               0\n","           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n","      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n","             ReLU-62            [-1, 512, 1, 1]               0\n","           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n","      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n","             ReLU-65            [-1, 512, 1, 1]               0\n","       BasicBlock-66            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n","           Linear-68                   [-1, 10]           5,130\n","================================================================\n","Total params: 11,181,642\n","Trainable params: 11,181,642\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 1.29\n","Params size (MB): 42.65\n","Estimated Total Size (MB): 43.95\n","----------------------------------------------------------------\n"]}],"source":["from torchvision import models\n","model_import = models.resnet18(pretrained=True, num_classes=10).to(DEVICE)\n","summary(model_import, (3, 32, 32))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pUam0mfLavpg"},"outputs":[],"source":["# Model, Optimizer 설정\n","optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":224250,"status":"ok","timestamp":1702979679460,"user":{"displayName":"YunSeok Choi","userId":"05693723351094624326"},"user_tz":-540},"id":"GM0Tm7RJHzv-","outputId":"df5e0786-aa12-4dd4-8bc8-36852441ec62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.556526\n","Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.664465\n","Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.188402\n","Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.288878\n","[1] Test Loss: 1.2128, Accuracy: 56.94%\n","Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.193257\n","Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.192611\n","Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.035982\n","Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.881990\n","[2] Test Loss: 1.0355, Accuracy: 63.43%\n","Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.940907\n","Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.756560\n","Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.170224\n","Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.817774\n","[3] Test Loss: 0.9862, Accuracy: 65.60%\n","Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.703970\n","Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.641945\n","Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.580945\n","Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.900586\n","[4] Test Loss: 0.9440, Accuracy: 67.62%\n","Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.810887\n","Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.666662\n","Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.814565\n","Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.600341\n","[5] Test Loss: 0.9710, Accuracy: 67.59%\n","Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.641715\n","Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.662218\n","Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.596094\n","Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.539774\n","[6] Test Loss: 1.1652, Accuracy: 63.60%\n","Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.626752\n","Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.406922\n","Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.652646\n","Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.741839\n","[7] Test Loss: 0.9542, Accuracy: 69.38%\n","Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.475525\n","Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.493789\n","Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.447166\n","Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.534925\n","[8] Test Loss: 1.0833, Accuracy: 67.94%\n","Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.614844\n","Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.301343\n","Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.383865\n","Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.459518\n","[9] Test Loss: 0.9262, Accuracy: 71.07%\n","Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.351272\n","Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.348000\n","Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.185257\n","Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.514607\n","[10] Test Loss: 0.9839, Accuracy: 70.76%\n"]}],"source":["# Train 구현\n","def train_one_epoch(model, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(DEVICE), target.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.cross_entropy(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 200 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","# Evaluation 구현\n","def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(DEVICE), target.to(DEVICE)\n","            output = model(data)\n","\n","            # 배치 오차를 합산\n","            test_loss += F.cross_entropy(output, target,\n","                                         reduction='sum').item()\n","\n","            # 가장 높은 값을 가진 인덱스가 바로 예측값\n","            pred = output.max(1, keepdim=True)[1]\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy\n","\n","for epoch in range(1, EPOCHS + 1):\n","    train_one_epoch(model, train_loader, optimizer, epoch)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","\n","    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n","          epoch, test_loss, test_accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeCUwKhQZ6x1"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1UpQVm6iH6RDOKjU-fl5gTfDsc80fOOxZ","timestamp":1627397450310}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}